<!DOCTYPE html>
<!-- saved from url=(0049)http://people.eng.unimelb.edu.au/tcohn/index.html -->
<html class="gr__people_eng_unimelb_edu_au"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    
    <title>Dr Vu Nguyen</title>

    <link href="./css/bootstrap.min.css" rel="stylesheet" media="screen">
    <link href="./css/bootstrap-glyphicons.css" rel="stylesheet">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <!-- MathJax -->
    <script async="" src="./js/analytics.js"></script><script type="text/javascript" src="./js/MathJax.js">
    </script>

    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
  <style type="text/css">.MathJax_Hover_Frame {border-radius: .25em; -webkit-border-radius: .25em; -moz-border-radius: .25em; -khtml-border-radius: .25em; box-shadow: 0px 0px 15px #83A; -webkit-box-shadow: 0px 0px 15px #83A; -moz-box-shadow: 0px 0px 15px #83A; -khtml-box-shadow: 0px 0px 15px #83A; border: 1px solid #A6D ! important; display: inline-block; position: absolute}
.MathJax_Menu_Button .MathJax_Hover_Arrow {position: absolute; cursor: pointer; display: inline-block; border: 2px solid #AAA; border-radius: 4px; -webkit-border-radius: 4px; -moz-border-radius: 4px; -khtml-border-radius: 4px; font-family: 'Courier New',Courier; font-size: 9px; color: #F0F0F0}
.MathJax_Menu_Button .MathJax_Hover_Arrow span {display: block; background-color: #AAA; border: 1px solid; border-radius: 3px; line-height: 0; padding: 4px}
.MathJax_Hover_Arrow:hover {color: white!important; border: 2px solid #CCC!important}
.MathJax_Hover_Arrow:hover span {background-color: #CCC!important}
</style><style type="text/css">#MathJax_About {position: fixed; left: 50%; width: auto; text-align: center; border: 3px outset; padding: 1em 2em; background-color: #DDDDDD; color: black; cursor: default; font-family: message-box; font-size: 120%; font-style: normal; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; z-index: 201; border-radius: 15px; -webkit-border-radius: 15px; -moz-border-radius: 15px; -khtml-border-radius: 15px; box-shadow: 0px 10px 20px #808080; -webkit-box-shadow: 0px 10px 20px #808080; -moz-box-shadow: 0px 10px 20px #808080; -khtml-box-shadow: 0px 10px 20px #808080; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
#MathJax_About.MathJax_MousePost {outline: none}
.MathJax_Menu {position: absolute; background-color: white; color: black; width: auto; padding: 2px; border: 1px solid #CCCCCC; margin: 0; cursor: default; font: menu; text-align: left; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; z-index: 201; box-shadow: 0px 10px 20px #808080; -webkit-box-shadow: 0px 10px 20px #808080; -moz-box-shadow: 0px 10px 20px #808080; -khtml-box-shadow: 0px 10px 20px #808080; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
.MathJax_MenuItem {padding: 2px 2em; background: transparent}
.MathJax_MenuArrow {position: absolute; right: .5em; padding-top: .25em; color: #666666; font-size: .75em}
.MathJax_MenuActive .MathJax_MenuArrow {color: white}
.MathJax_MenuArrow.RTL {left: .5em; right: auto}
.MathJax_MenuCheck {position: absolute; left: .7em}
.MathJax_MenuCheck.RTL {right: .7em; left: auto}
.MathJax_MenuRadioCheck {position: absolute; left: 1em}
.MathJax_MenuRadioCheck.RTL {right: 1em; left: auto}
.MathJax_MenuLabel {padding: 2px 2em 4px 1.33em; font-style: italic}
.MathJax_MenuRule {border-top: 1px solid #CCCCCC; margin: 4px 1px 0px}
.MathJax_MenuDisabled {color: GrayText}
.MathJax_MenuActive {background-color: Highlight; color: HighlightText}
.MathJax_MenuDisabled:focus, .MathJax_MenuLabel:focus {background-color: #E8E8E8}
.MathJax_ContextMenu:focus {outline: none}
.MathJax_ContextMenu .MathJax_MenuItem:focus {outline: none}
#MathJax_AboutClose {top: .2em; right: .2em}
.MathJax_Menu .MathJax_MenuClose {top: -10px; left: -10px}
.MathJax_MenuClose {position: absolute; cursor: pointer; display: inline-block; border: 2px solid #AAA; border-radius: 18px; -webkit-border-radius: 18px; -moz-border-radius: 18px; -khtml-border-radius: 18px; font-family: 'Courier New',Courier; font-size: 24px; color: #F0F0F0}
.MathJax_MenuClose span {display: block; background-color: #AAA; border: 1.5px solid; border-radius: 18px; -webkit-border-radius: 18px; -moz-border-radius: 18px; -khtml-border-radius: 18px; line-height: 0; padding: 8px 0 6px}
.MathJax_MenuClose:hover {color: white!important; border: 2px solid #CCC!important}
.MathJax_MenuClose:hover span {background-color: #CCC!important}
.MathJax_MenuClose:hover:focus {outline: none}
</style><style type="text/css">.MathJax_Preview .MJXf-math {color: inherit!important}
</style><style type="text/css">.MJX_Assistive_MathML {position: absolute!important; top: 0; left: 0; clip: rect(1px, 1px, 1px, 1px); padding: 1px 0 0 0!important; border: 0!important; height: 1px!important; width: 1px!important; overflow: hidden!important; display: block!important; -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none}
.MJX_Assistive_MathML.MJX_Assistive_MathML_Block {width: 100%!important}
</style><style type="text/css">#MathJax_Zoom {position: absolute; background-color: #F0F0F0; overflow: auto; display: block; z-index: 301; padding: .5em; border: 1px solid black; margin: 0; font-weight: normal; font-style: normal; text-align: left; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; -webkit-box-sizing: content-box; -moz-box-sizing: content-box; box-sizing: content-box; box-shadow: 5px 5px 15px #AAAAAA; -webkit-box-shadow: 5px 5px 15px #AAAAAA; -moz-box-shadow: 5px 5px 15px #AAAAAA; -khtml-box-shadow: 5px 5px 15px #AAAAAA; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
#MathJax_ZoomOverlay {position: absolute; left: 0; top: 0; z-index: 300; display: inline-block; width: 100%; height: 100%; border: 0; padding: 0; margin: 0; background-color: white; opacity: 0; filter: alpha(opacity=0)}
#MathJax_ZoomFrame {position: relative; display: inline-block; height: 0; width: 0}
#MathJax_ZoomEventTrap {position: absolute; left: 0; top: 0; z-index: 302; display: inline-block; border: 0; padding: 0; margin: 0; background-color: white; opacity: 0; filter: alpha(opacity=0)}
</style><style type="text/css">.MathJax_Preview {color: #888}
#MathJax_Message {position: fixed; left: 1em; bottom: 1.5em; background-color: #E6E6E6; border: 1px solid #959595; margin: 0px; padding: 2px 8px; z-index: 102; color: black; font-size: 80%; width: auto; white-space: nowrap}
#MathJax_MSIE_Frame {position: absolute; top: 0; left: 0; width: 0px; z-index: 101; border: 0px; margin: 0px; padding: 0px}
.MathJax_Error {color: #CC0000; font-style: italic}
</style><style type="text/css">.MJXp-script {font-size: .8em}
.MJXp-right {-webkit-transform-origin: right; -moz-transform-origin: right; -ms-transform-origin: right; -o-transform-origin: right; transform-origin: right}
.MJXp-bold {font-weight: bold}
.MJXp-italic {font-style: italic}
.MJXp-scr {font-family: MathJax_Script,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-frak {font-family: MathJax_Fraktur,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-sf {font-family: MathJax_SansSerif,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-cal {font-family: MathJax_Caligraphic,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-mono {font-family: MathJax_Typewriter,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-largeop {font-size: 150%}
.MJXp-largeop.MJXp-int {vertical-align: -.2em}
.MJXp-math {display: inline-block; line-height: 1.2; text-indent: 0; font-family: 'Times New Roman',Times,STIXGeneral,serif; white-space: nowrap; border-collapse: collapse}
.MJXp-display {display: block; text-align: center; margin: 1em 0}
.MJXp-math span {display: inline-block}
.MJXp-box {display: block!important; text-align: center}
.MJXp-box:after {content: " "}
.MJXp-rule {display: block!important; margin-top: .1em}
.MJXp-char {display: block!important}
.MJXp-mo {margin: 0 .15em}
.MJXp-mfrac {margin: 0 .125em; vertical-align: .25em}
.MJXp-denom {display: inline-table!important; width: 100%}
.MJXp-denom > * {display: table-row!important}
.MJXp-surd {vertical-align: top}
.MJXp-surd > * {display: block!important}
.MJXp-script-box > *  {display: table!important; height: 50%}
.MJXp-script-box > * > * {display: table-cell!important; vertical-align: top}
.MJXp-script-box > *:last-child > * {vertical-align: bottom}
.MJXp-script-box > * > * > * {display: block!important}
.MJXp-mphantom {visibility: hidden}
.MJXp-munderover {display: inline-table!important}
.MJXp-over {display: inline-block!important; text-align: center}
.MJXp-over > * {display: block!important}
.MJXp-munderover > * {display: table-row!important}
.MJXp-mtable {vertical-align: .25em; margin: 0 .125em}
.MJXp-mtable > * {display: inline-table!important; vertical-align: middle}
.MJXp-mtr {display: table-row!important}
.MJXp-mtd {display: table-cell!important; text-align: center; padding: .5em 0 0 .5em}
.MJXp-mtr > .MJXp-mtd:first-child {padding-left: 0}
.MJXp-mtr:first-child > .MJXp-mtd {padding-top: 0}
.MJXp-mlabeledtr {display: table-row!important}
.MJXp-mlabeledtr > .MJXp-mtd:first-child {padding-left: 0}
.MJXp-mlabeledtr:first-child > .MJXp-mtd {padding-top: 0}
.MJXp-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 1px 3px; font-style: normal; font-size: 90%}
.MJXp-scale0 {-webkit-transform: scaleX(.0); -moz-transform: scaleX(.0); -ms-transform: scaleX(.0); -o-transform: scaleX(.0); transform: scaleX(.0)}
.MJXp-scale1 {-webkit-transform: scaleX(.1); -moz-transform: scaleX(.1); -ms-transform: scaleX(.1); -o-transform: scaleX(.1); transform: scaleX(.1)}
.MJXp-scale2 {-webkit-transform: scaleX(.2); -moz-transform: scaleX(.2); -ms-transform: scaleX(.2); -o-transform: scaleX(.2); transform: scaleX(.2)}
.MJXp-scale3 {-webkit-transform: scaleX(.3); -moz-transform: scaleX(.3); -ms-transform: scaleX(.3); -o-transform: scaleX(.3); transform: scaleX(.3)}
.MJXp-scale4 {-webkit-transform: scaleX(.4); -moz-transform: scaleX(.4); -ms-transform: scaleX(.4); -o-transform: scaleX(.4); transform: scaleX(.4)}
.MJXp-scale5 {-webkit-transform: scaleX(.5); -moz-transform: scaleX(.5); -ms-transform: scaleX(.5); -o-transform: scaleX(.5); transform: scaleX(.5)}
.MJXp-scale6 {-webkit-transform: scaleX(.6); -moz-transform: scaleX(.6); -ms-transform: scaleX(.6); -o-transform: scaleX(.6); transform: scaleX(.6)}
.MJXp-scale7 {-webkit-transform: scaleX(.7); -moz-transform: scaleX(.7); -ms-transform: scaleX(.7); -o-transform: scaleX(.7); transform: scaleX(.7)}
.MJXp-scale8 {-webkit-transform: scaleX(.8); -moz-transform: scaleX(.8); -ms-transform: scaleX(.8); -o-transform: scaleX(.8); transform: scaleX(.8)}
.MJXp-scale9 {-webkit-transform: scaleX(.9); -moz-transform: scaleX(.9); -ms-transform: scaleX(.9); -o-transform: scaleX(.9); transform: scaleX(.9)}
.MathJax_PHTML .noError {vertical-align: ; font-size: 90%; text-align: left; color: black; padding: 1px 3px; border: 1px solid}
</style><style id="style-1-cropbar-clipper">/* Copyright 2014 Evernote Corporation. All rights reserved. */
.en-markup-crop-options {
    top: 18px !important;
    left: 50% !important;
    margin-left: -100px !important;
    width: 200px !important;
    border: 2px rgba(255,255,255,.38) solid !important;
    border-radius: 4px !important;
}

.en-markup-crop-options div div:first-of-type {
    margin-left: 0px !important;
}
</style></head>
  <body data-gr-c-s-loaded="true"><div id="MathJax_Message" style="display: none;"></div>
    <!-- JavaScript plugins (requires jQuery) -->
    <script src="./js/jquery.js"></script>
    <!-- Include all compiled plugins (below), or include individual files as needed -->
    <script src="./js/bootstrap.min.js"></script>

    <div class="container">
      <div class="row">
        <div class="col-sm-2">
          <br><br> 
<img src="./img/person/Vu_2016.jpg" class="img-responsive" alt="climb-sm">
<ul class="nav navbar-inverse">
  <li>
    <a href="index.html">Home</a>
  </li>
  <li>
    <a href="publications.html">Publications</a>
  </li>

</ul>


        </div>
        <div class="col-sm-10">
          <div class="page-header">
  <div class="row">
    <div class="col-sm-3">
      <h3>Dr Vu Nguyen</h3>
      <address>
        <br>
        <br>
      </address>
    </div>
    <div class="col-sm-9">
      <br>
      <div class="row">
        <div class="col-sm-4">
          Associate Research Fellow <br>
        </div>
        <div class="col-sm-6">
          <a href="http://www.deakin.edu.au/research/prada">Center for Pattern Recognition and Data Analytics</a><br>
          <a href="http://deakin.edu.au">Deakin University</a><br>
        </div>
      </div>
    </div>
  </div>
  <div class="row">
    <div class="col-sm-2">
	<script type="text/javascript"><!--
	</script><a href="mailto:v.nguyen@deakin.edu.au"><span class="glyphicon glyphicon-envelope"></span></a> Email
	<noscript>&lt;IMG alt="E-mail" border=0 src="./email.jpg"&gt;</noscript>
    </div>
	
    <div class="col-sm-2">
        <a href="https://scholar.google.com.au/citations?user=5RQyC9cAAAAJ&hl=en">
          <img src="./img/ico/gs.png" alt="">
        </a>
        Google Scholar
    </div>
	
	<div class="col-sm-2">
        <a href="https://github.com/ntienvu">
          <img src="./img/ico/github_icon.png" alt="">
        </a>
        Github
    </div>
  </div>
</div>

<p>
 I am currently working as a Postdoc at <a href="http://www.deakin.edu.au/research/prada">PRADA</a>, <a href="http://www.deakin.edu.au/">Deakin University</a>. 
 I am working with <a href="http://prada-research.net/~svetha/">Prof Svetha Venkatesh</a> and <a href="http://prada-research.net/~dinh/">Prof Dinh Phung</a>.
</p>

<h4>Research Interests</h4>
<ul>

      <li>
		Bayesian Nonparametric: Dirichlet Process Mixture, Hierarchical Dirichlet Process, Nested Dirichlet Process
      </li>
      <li>
		Multilevel Modelling: Multilevel Clustering, Multilevel Regression
      </li>
	    <li>
			  Bayesian Optimization: Batch Bayesian Optimization
      </li>
	  
      <li>
	  Label-drift Classification
      </li>
	  	  
      <li>
		Abnormality Detection
      </li>
	  
</ul>

<h4>Qualifications</h4>
<ul>

      <li>
        Doctor of Philosophy. 02/2012-05/2015: <br>
		<a href="http://www.deakin.edu.au/">Deakin University</a>. 
		Supervisors: <a href="http://prada-research.net/~dinh/">Prof Dinh Phung</a> and <a href="http://prada-research.net/~svetha/">Prof Svetha Venkatesh</a>  <br>
		Thesis: Bayesian Nonparametric Multilevel Modeling and Applications.

      </li>

      <li>
        Bachelor of Science (First Class Honour) of Information Technology. 09/2007-09/2011: <br> <a href="http://www.hcmus.edu.vn/en/index.php">University of Science - Vietnam National University - HCMC</a>.
		Supervisors: Prof Bac Le  <br>
		Thesis: Interactive Image Segmentation using Graph-cut.
      </li>
	  
</ul>

<h4>Selected Papers</h4>



<div class="media">
  <a class="pull-left thumbnail" href="https://bayesopt.github.io/papers/2016/Nguyen.pdf">
    <img src="./img/paper/rsz_global_optimization.png" alt="">
  </a>
  <div class="media-body">
    <strong>V. Nguyen</strong>, S. K. Gupta, S. Rana, C. Li, S. Venkatesh <br>
	    <strong>Think Globally, Act Locally: a Local Strategy for Bayesian Optimization</strong><br>

        In           <i>NIPS Workshop on Bayesian Optimization </i>, (<strong>NIPS</strong>),    2016.<br>
				  
      <a data-toggle="modal" href="http://prada-research.net/~tienvu/#abstractNIPS16_ELI" class="label label-default">Abstract</a>
      <!-- Modal -->
      <div class="modal fade" id="abstractNIPS16_ELI" tabindex="-1" role="dialog" aria-hidden="true"> <div class="modal-dialog">
          <div class="modal-content">
            <div class="modal-header">
              <button type="button" class="close" data-dismiss="modal" aria-hidden="true">×</button>
              <h4 class="modal-title">Think Globally, Act Locally: a Local Strategy for Bayesian Optimization</h4>
            </div>
            <div class="modal-body">
			Bayesian optimization (BO) is a sample-efficient method for improving the performance of machine learning algorithms and laboratory experiments. We exploit the local property in BO to develop a new acquisition function, the expected local
improvement (ELI) as an alternative to Expected Improvement (EI), aiming to address two underlying issues. First, we reduce the flatland issue in high dimension and second we allow greater explorative choices for batch BO unlike the existing strategies. We derive the convergence analysis using simple regret bound. We further demonstrate that the proposed strategy gains substantial performance improvement over the state-of-the-art baselines using the benchmark functions and
real experiments on sequential and batch BO.
</div>
          </div><!-- /.modal-content -->
        </div><!-- /.modal-dialog -->
      </div><!-- /.modal --> 
	  	  	  	  	  	          <a href="https://bayesopt.github.io/papers/2016/Nguyen.pdf" class="label label-info">PDF</a>

  </div>
</div>



<div class="media">
  <a class="pull-left thumbnail" href="http://proceedings.mlr.press/v63/nguyen93.html">
    <img src="./img/paper/acml2016.png" alt="">
  </a>
  <div class="media-body">
    <strong>V. Nguyen</strong>, S. K. Gupta, S. Rana, C. Li, S. Venkatesh <br>
	    <strong>A Bayesian Nonparametric Approach for Multi-label Classification</strong><br>

        In           <i>Proceedings of The 8th Asian Conference on Machine Learning</i>, (<strong>ACML</strong>), pp 254-269,    2016.<br>
				  
      <a data-toggle="modal" href="http://prada-research.net/~tienvu/#abstractACML_BNMC" class="label label-default">Abstract</a>
      <!-- Modal -->
      <div class="modal fade" id="abstractACML_BNMC" tabindex="-1" role="dialog" aria-hidden="true"> <div class="modal-dialog">
          <div class="modal-content">
            <div class="modal-header">
              <button type="button" class="close" data-dismiss="modal" aria-hidden="true">×</button>
              <h4 class="modal-title">A Bayesian Nonparametric Approach for Multi-label Classification</h4>
            </div>
            <div class="modal-body">
			Many real-world applications require multi-label classification where multiple target labels
are assigned to each instance. In multi-label classification, there exist the intrinsic correlations
between the labels and features. These correlations are beneficial for multi-label
classification task since they reflect the coexistence of the input and output spaces that can
be exploited for prediction. Traditional classification methods have attempted to reveal
these correlations in different ways. However, existing methods demand expensive computation
complexity for finding such correlation structures. Furthermore, these approaches
can not identify the suitable number of label-feature correlation patterns. In this paper, we
propose a Bayesian nonparametric (BNP) framework for multi-label classification that can
automatically learn and exploit the unknown number of multi-label correlation. We utilize
the recent techniques in stochastic inference to derive the cheap (but efficient) posterior
inference algorithm for the model. In addition, our model can naturally exploit the useful
information from missing label samples. Furthermore, we extend the model to update parameters
in an online fashion that highlights the flexibility of our model against the existing
approaches. We compare our method with the state-of-the-art multi-label classification algorithms
on real-world datasets using both complete and missing label settings. Our model
achieves better classification accuracy while our running time is consistently much faster
than the baselines in an order of magnitude.
</div>
          </div><!-- /.modal-content -->
        </div><!-- /.modal-dialog -->
      </div><!-- /.modal --> 
	  	  	  	  	          <a href="http://proceedings.mlr.press/v63/nguyen93.html" class="label label-info">PDF</a>

	  <a href="https://github.com/ntienvu/ACML2016_BNMC" class="label label-success">Code</a>
		<a href="https://www.youtube.com/watch?v=-EE-I2IpQbo" class="label label-success">Youtube Demo</a>
		<a href="" class="label label-danger">Best Paper Runner Up Award</a>
		<a href="" class="label label-danger">Best Poster Award</a>

	  
  </div>
</div>




  
<div class="media">
  <a class="pull-left thumbnail" href="http://ieeexplore.ieee.org/document/7837957/">
    <img src="./img/paper/rsz_global_optimization.png" alt="">
  </a>
  <div class="media-body">
    <strong>V. Nguyen</strong>, S. Rana, S. K. Gupta, C. Li, S. Venkatesh <br>
	    <strong>Budgeted Batch Bayesian Optimization</strong><br>

        In           <i>Proceedings of the IEEE International Conference on Data Mining</i>, (<strong>ICDM</strong>),  pp 1107-1112,    2016.<br>
				  
      <a data-toggle="modal" href="http://prada-research.net/~tienvu/#abstractB3O_ICDM" class="label label-default">Abstract</a>
      <!-- Modal -->
      <div class="modal fade" id="abstractB3O_ICDM" tabindex="-1" role="dialog" aria-hidden="true"> <div class="modal-dialog">
          <div class="modal-content">
            <div class="modal-header">
              <button type="button" class="close" data-dismiss="modal" aria-hidden="true">×</button>
              <h4 class="modal-title">Budgeted Batch Bayesian Optimization</h4>
            </div>
            <div class="modal-body">
			Parameter settings profoundly impact the performance
of machine learning algorithms and laboratory experiments.
The classical trial-error methods are exponentially expensive
in large parameter spaces, and Bayesian optimization (BO)
offers an elegant alternative for global optimization of black box
functions. In situations where the functions can be evaluated
at multiple points simultaneously, batch Bayesian optimization
is used. Current batch BO approaches are restrictive in fixing
the number of evaluations per batch, and this can be wasteful
when the number of specified evaluations is larger than the
number of real maxima in the underlying acquisition function.
We present the budgeted batch Bayesian optimization (B3O) for
hyper-parameter tuning and experimental design - we identify
the appropriate batch size for each iteration in an elegant
way. In particular, we use the infinite Gaussian mixture model
(IGMM) for automatically identifying the number of peaks in
the underlying acquisition functions. We solve the intractability
of estimating the IGMM directly from the acquisition function
by formulating the batch generalized slice sampling to efficiently
draw samples from the acquisition function. We perform extensive
experiments for benchmark functions and two real world
applications - machine learning hyper-parameter tuning and
experimental design for alloy hardening. We show empirically
that the proposed B3O outperforms the existing fixed batch BO
approaches in finding the optimum whilst requiring a fewer
number of evaluations, thus saving cost and time.
</div>
          </div><!-- /.modal-content -->
        </div><!-- /.modal-dialog -->
      </div><!-- /.modal --> 
	  	  	          <a href="http://ieeexplore.ieee.org/document/7837957/" class="label label-info">PDF</a>

	  <a href="https://github.com/ntienvu/ICDM2016_B3O" class="label label-success">Code</a>
	  
  </div>
</div>




<div class="media">
  <a class="pull-left thumbnail" href="http://ieeexplore.ieee.org/document/7837958/">
    <img src="./img/paper/ICDM2016_OLR.png" alt="">
  </a>
  <div class="media-body">
    <strong>V. Nguyen</strong>, T. D. Nguyen, T. Le, S. Venkatesh, D. Phung.  <br>
	    <strong>One-pass Logistic Regression for Label-drift and Large-scale Classification on Distributed Systems </strong><br>

        In           <i>Proceedings of the IEEE International Conference on Data Mining</i>, (<strong>ICDM</strong>),  pp 1113-1118,    2016.<br>
				  
      <a data-toggle="modal" href="http://prada-research.net/~tienvu/#abstractOLR_ICDM" class="label label-default">Abstract</a>
      <!-- Modal -->
      <div class="modal fade" id="abstractOLR_ICDM" tabindex="-1" role="dialog" aria-hidden="true"> <div class="modal-dialog">
          <div class="modal-content">
            <div class="modal-header">
              <button type="button" class="close" data-dismiss="modal" aria-hidden="true">×</button>
              <h4 class="modal-title">One-pass Logistic Regression for Label-drift and Large-scale Classification on Distributed Systems</h4>
            </div>
            <div class="modal-body">
			Logistic regression (LR) is at the cornerstone of classification. Its extension for multiclass classification is the
workhorse in industry, where a set of predefined classes is required. The model, however, fails to work in the case where
the class labels are not known in advance, a problem we term label-drift classification, in a similar spirit of the so-called conceptdrift
problem in the literature. Label-drift classification problem naturally occurs in many applications, especially in the context
of streaming and online settings where the incoming data may contain samples categorized with new classes that have not
been previously seen. Additionally, in the wave of big data, traditional LR methods may fail due to their expense of running
time and label-drift requirements. In this paper, we introduce a novel variant of LR, namely one-pass logistic regression (OLR)
to offer a principled treatment for large-scale and label-drift classifications. Our key contribution is the derivation of sufficient
statistic update for MAP estimation of Polya-Gamma augmentation for LR. Manipulating these sufficient statistics is convenient,
allowing our proposed method to efficiently perform the labeldrift classification under an online setting without retraining the
model from scratch. To handle large-scale classification for big data, we further extend our OLR to a distributed setting for
parallelization, termed sparkling OLR (Spark-OLR). We demonstrate the scalability of our proposed methods on large-scale
datasets with more than one hundred million data points. The experimental results show that the predictive performances of our
methods are comparable or better than those of state-of-the-art baselines whilst the execution time is much faster at an order of
magnitude. To measure the inherent trade-off between speed and accuracy, we propose quadrant visualization and quadrant score,
on which our proposed model outperforms other methods on all datasets. In addition, the OLR and Spark-OLR are invariant
to data shuffling and have no hyperparameter to tune that significantly benefits data practitioners and overcomes the curse
of big data cross-validation to select optimal hyperparameters.
</div>
          </div><!-- /.modal-content -->
        </div><!-- /.modal-dialog -->
      </div><!-- /.modal --> 
	  	          <a href="http://ieeexplore.ieee.org/document/7837958/" class="label label-info">PDF</a>

	  <a href="https://github.com/ntienvu/ICDM2016_OLR" class="label label-success">Code</a>
  </div>
</div>





<div class="media">
  <a class="pull-left thumbnail" href="https://papers.nips.cc/paper/6560-dual-space-gradient-descent-for-online-learning.pdf">
    <img src="./img/paper/NIPS2016.png" alt="">
  </a>
  <div class="media-body">
    T. Le, T.D. Nguyen,<strong>V. Nguyen</strong>, D. Phung.  <br>
	    <strong>Dual Space Gradient Descent for Online Learning</strong><br>

        In           <i>Advances in Neural Information Processing Systems</i>, (<strong>NIPS</strong>),  pp 4583-4591,    2016.<br>
				  
      <a data-toggle="modal" href="http://prada-research.net/~tienvu/#abstractNIPS" class="label label-default">Abstract</a>
      <!-- Modal -->
      <div class="modal fade" id="abstractNIPS" tabindex="-1" role="dialog" aria-hidden="true"> <div class="modal-dialog">
          <div class="modal-content">
            <div class="modal-header">
              <button type="button" class="close" data-dismiss="modal" aria-hidden="true">×</button>
              <h4 class="modal-title">Dual Space Gradient Descent for Online Learning</h4>
            </div>
            <div class="modal-body">
			One crucial goal in kernel online learning is to bound the model size. Common
approaches employ budget maintenance procedures to restrict the model sizes using
removal, projection, or merging strategies. Although projection and merging, in the
literature, are known to be the most effective strategies, they demand extensive com
putation whilst removal strategy fails to retain information of the removed vectors.
An alternative way to address the model size problem is to apply random features
to approximate the kernel function. This allows the model to be maintained directly
in the random feature space, hence effectively resolve the curse of kernelization.
However, this approach still suffers from a serious shortcoming as it needs to use a
high dimensional random feature space to achieve a sufficiently accurate kernel
 approximation. Consequently, it leads to a significant increase in the computational
 cost. To address all of these aforementioned challenges, we present in this paper
 the Dual Space Gradient Descent (DualSGD), a novel framework that utilizes
 random features as an auxiliary space to maintain information from data points
 removed during budget maintenance. Consequently, our approach permits the
budget to be maintained in a simple, direct and elegant way while simultaneously
 mitigating the impact of the dimensionality issue on learning performance. We
 further provide convergence analysis and extensively conduct experiments on five
 real-world datasets to demonstrate the predictive performance and scalability of
 our proposed method in comparison with the state-of-the-art baselines.
</div>
          </div><!-- /.modal-content -->
        </div><!-- /.modal-dialog -->
      </div><!-- /.modal --> 
	  
	          <a href="https://papers.nips.cc/paper/6560-dual-space-gradient-descent-for-online-learning.pdf" class="label label-info">PDF</a>

			  
	    </div>
</div>



  
<div class="media">
  <a class="pull-left thumbnail" href="http://jmlr.org/proceedings/papers/v51/le16.pdf">
    <img src="./img/paper/AISTATS2016.jpg" alt="">
  </a>
  <div class="media-body">
    T Le, <strong>V Nguyen</strong>, TD Nguyen, D Phung.  <br>
	    <strong>Nonparametric Budgeted Stochastic Gradient Descent</strong><br>

        In           <i>Proceedings of the 19th International Conference on Artificial Intelligence and Statistics</i>, (<strong>AISTATS</strong>),  pp 654-572,    2016.<br>
				  
      <a data-toggle="modal" href="http://http://prada-research.net/~tienvu/#abstractabstractNonparametricBudgetedStochasticGradientDescent" class="label label-default">Abstract</a>
      <!-- Modal -->
      <div class="modal fade" id="abstractabstractNonparametricBudgetedStochasticGradientDescent" tabindex="-1" role="dialog" aria-hidden="true"> <div class="modal-dialog">
          <div class="modal-content">
            <div class="modal-header">
              <button type="button" class="close" data-dismiss="modal" aria-hidden="true">×</button>
              <h4 class="modal-title">Nonparametric Budgeted Stochastic Gradient Descent</h4>
            </div>
            <div class="modal-body">
One of the most challenging problems in kernel online learning is to bound the model size. 
Budgeted kernel online learning addresses this issue by bounding the model size to a predefined budget. 
However, determining an appropriate value for such predefined budget is arduous. 
In this paper, we propose the Nonparametric Budgeted Stochastic Gradient Descent that allows the model size to automatically grow with data in a principled way. 
We provide theoretical analysis to show that our framework is guaranteed to converge for a large collection of loss functions 
(e.g. Hinge, Logistic, L2, L1, and ε-insensitive) which enables the proposed algorithm to perform both classification and regression tasks without hurting the ideal convergence rate O(1/T) 
of the standard Stochastic Gradient Descent. We validate our algorithm on the real-world datasets to consolidate the theoretical claims.            </div>
          </div><!-- /.modal-content -->
        </div><!-- /.modal-dialog -->
      </div><!-- /.modal --> 
	  
        <a href="http://jmlr.org/proceedings/papers/v51/le16.pdf" class="label label-info">PDF</a>
      <a href="https://github.com/ntienvu/NonparametricBudgetedSGD" class="label label-success">Code</a>
  </div>
</div>


<div class="media">

  <a class="pull-left thumbnail" href="http://ieeexplore.ieee.org/xpl/login.jsp?tp=&arnumber=7456501&url=http%3A%2F%2Fieeexplore.ieee.org%2Fxpls%2Fabs_all.jsp%3Farnumber%3D7456501">
    <img src="./img/paper/PERCOM2016.jpg" alt="">
  </a>
  <div class="media-body">
    T Nguyen, <strong>V Nguyen</strong>, FD Salim, D Phung.  <br>
	    <strong>SECC: Simultaneous Extraction of Context and Community from Pervasive Signals</strong><br>
        In           <i>Proceedings of 2016 IEEE International Conference on Pervasive Computing and Communications</i>, (<strong>PERCOM</strong>), pp 1-9,  2016.<br>
				  
      <a data-toggle="modal" href="http://http://prada-research.net/~tienvu/#abstractSECC" class="label label-default">Abstract</a>
      <!-- Modal -->
      <div class="modal fade" id="abstractSECC" tabindex="-1" role="dialog" aria-hidden="true"> <div class="modal-dialog">
          <div class="modal-content">
            <div class="modal-header">
              <button type="button" class="close" data-dismiss="modal" aria-hidden="true">×</button>
              <h4 class="modal-title">SECC: Simultaneous Extraction of Context and Community from Pervasive Signals</h4>
            </div>
            <div class="modal-body">
Understanding user contexts and group structures plays a central role in pervasive computing. These contexts and community structures are complex to mine from data collected in the 
wild due to the unprecedented growth of data, noise, uncertainties and complexities. Typical existing approaches would first extract the latent patterns to explain the human dynamics 
or behaviors and then use them as the way to consistently formulate numerical representations for community detection, often via a clustering method. While being able to capture highorder 
and complex representations, these two steps are performed separately. More importantly, they face a fundamental difficulty in determining the correct number of latent patterns and communities. 
This paper presents an approach that seamlessly addresses these challenges to simultaneously discover latent patterns and communities in a unified Bayesian nonparametric framework. 
Our Simultaneous Extraction of Context and Community (SECC) model roots in the nested Dirichlet process theory which allows nested structure to be built to explain data at multiple levels. 
We demonstrate our framework on three public datasets where the advantages of the proposed approach are validated.            </div>
          </div><!-- /.modal-content -->
        </div><!-- /.modal-dialog -->
      </div><!-- /.modal --> 
	  
        <a href="http://ieeexplore.ieee.org/xpl/login.jsp?tp=&arnumber=7456501&url=http%3A%2F%2Fieeexplore.ieee.org%2Fxpls%2Fabs_all.jsp%3Farnumber%3D7456501" class="label label-info">PDF</a>
  </div>
</div>



<div class="media">
  <a class="pull-left thumbnail" href="http://jmlr.org/proceedings/papers/v32/nguyenb14.html">
    <img src="./img/paper/ICML2014.jpg" alt="">
  </a>
  <div class="media-body">
   <strong>V Nguyen</strong>, D. Phung, L. Nguyen, S. Venkatesh and H. Bui   <br>
       <strong>Bayesian Nonparametric Multilevel Clustering with Group-Level Contexts.</strong><br>

        In           <i>Proceedings of The 31st International Conference on Machine Learning</i> (<strong>ICML</strong>), pp. 288–296, 2014.<br>
				  
      <a data-toggle="modal" href="http://http://prada-research.net/~tienvu/#abstractICML14" class="label label-default">Abstract</a>
      <!-- Modal -->
      <div class="modal fade" id="abstractICML14" tabindex="-1" role="dialog" aria-hidden="true"> <div class="modal-dialog">
          <div class="modal-content">
            <div class="modal-header">
              <button type="button" class="close" data-dismiss="modal" aria-hidden="true">×</button>
              <h4 class="modal-title">Bayesian Nonparametric Multilevel Clustering with Group-Level Contexts</h4>
            </div>
            <div class="modal-body">
We present a Bayesian nonparametric framework for multilevel clustering which utilizes group-level context information to simultaneously discover low-dimensional structures of the group contents 
and partitions groups into clusters. Using the Dirichlet process as the building block, our model constructs a product base-measure with a nested structure to accommodate content and context 
observations at multiple levels. The proposed model possesses properties that link the nested Dirichlet processes (nDP) and the Dirichlet process mixture models (DPM) in an interesting way: 
integrating out all contents results in the DPM over contexts, whereas integrating out group-speciﬁc contexts results in the nDP mixture over content variables. We provide a Polya-urn view of 
the model and an efﬁcient collapsed Gibbs inference procedure. 
Extensive experiments on real-world datasets demonstrate the advantage of utilizing context information via our model in both text and image domains.
            </div>
          </div><!-- /.modal-content -->
        </div><!-- /.modal-dialog -->
      </div><!-- /.modal --> 
	  
        <a href="http://jmlr.org/proceedings/papers/v32/nguyenb14.html" class="label label-info">PDF</a>

  </div>
</div>



		  <br>
	  <br> 
	  <br>
	  <br>
	  <br>
	  <br>
	  <br>
	  
<blockquote>
        <a href="http://s11.flagcounter.com/more/XfDO"><img
src="http://s11.flagcounter.com/count/XfDO/bg_FFFFFF/txt_000000/border_CCCCCC/columns_2/maxflags_12/viewers_0/labels_0/pageviews_0/flags_0/"
            alt="free counters" border="0"></a>
        <!-- hitwebcounter Code START --> <a
          href="http://www.hitwebcounter.com/counterresources.php"
          target="_blank"> <img
src="http://hitwebcounter.com/counter/counter.php?page=4530260&amp;style=0025&amp;nbdigits=5&amp;type=page&amp;initCount=0"
            title="visitors base of the site" alt="visitors base of the
            site" border="0"> </a><br>
        <!-- hitwebcounter.com --><a
          href="http://www.hitwebcounter.com/" title="Web Counter"
          target="_blank" style="font-family: Arial, Helvetica,
          sans-serif; font-size: 15px; color: #908E86; text-decoration:
          none ;"><code>Web Counter</code> </a> </blockquote>

      <footer class="text-center text-muted">
        <hr>
        Last updated June 15, 2017.<br>
	Based on the code of 
        <a href="https://github.com/alopez/alopez.github.com">Adam Lopez</a>.<br>
        Created with 
        <a href="http://git-scm.com/">git</a>,
        <a href="http://jekyllrb.com/">jekyll</a>,
        <a href="http://getbootstrap.com/">bootstrap</a>,
        and <a href="http://www.vim.org/">vim</a>.<br> 
        <br><br>
      </footer>
    </div>
    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
        (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
         m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
      ga('create', 'UA-46770577-1', 'jhu.edu');
      ga('send', 'pageview');
    </script>
  


</body></html>